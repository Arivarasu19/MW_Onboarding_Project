{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e20d3a13-51a6-4c8d-8b75-49a7b6b15e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import lightgbm as lgb\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad13a3e3-d595-4a1e-9151-96bc3b7306a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'/Users/arivarasuperumal/downloads/Onboarding_project_MW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13c89268-b980-4501-8a53-6684a1bb072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('Lending_Club_Data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4910765-f866-4ac6-9b6f-f9c87e06ef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Max_credit_age'] = round((pd.to_datetime(\"now\") - data['earliest_cr_line'])/np.timedelta64(1,'Y'),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d941b11d-3cf6-421b-90d9-8a58ea400fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ratio_open_total_acc'] = round(data['open_acc']/data['total_acc'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ec7410d-63d6-478b-a642-e237d4a2d805",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['emp_length'] = data['emp_length'].apply(lambda x: x/11 if x in [11,22,33] else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ef105b1-65c2-4703-8864-8247b14499c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['purpose', 'id', 'emp_title', 'zip_code'],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e686fd5-6689-4745-bf2d-1192464fc439",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Notes'] = data['Notes'].astype(str)\n",
    "data[\"Notes_length\"] = data['Notes'].apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f262050-f5c8-402b-8d5d-b92c4db047b7",
   "metadata": {},
   "source": [
    "### Subjectivity & Polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aca24dc3-69fd-428a-9cfe-9f6a0ad0b1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def get_polarity(text):\n",
    "    try:\n",
    "        textblob = TextBlob(unicode(text, 'utf-8'))\n",
    "        pol = textblob.sentiment.polarity\n",
    "    except:\n",
    "        pol = 0.0\n",
    "    return pol\n",
    "\n",
    "def get_subjectivity(text):\n",
    "    try:\n",
    "        textblob = TextBlob(unicode(text, 'utf-8'))\n",
    "        subj = textblob.sentiment.subjectivity\n",
    "    except:\n",
    "        subj = 0.0\n",
    "    return subj\n",
    "\n",
    "data['polarity'] = data['Notes'].apply(get_polarity)\n",
    "data['subjectivity'] = data['Notes'].apply(get_subjectivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560eed16-6bca-4da8-81eb-ad33f14dfc5f",
   "metadata": {},
   "source": [
    "### TF-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66fb2eb3-fdcb-4da9-afae-41930a06582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.decomposition import LatentDirichletAllocation\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Notes = list(data['Notes'].values)\n",
    "\n",
    "# vect_word = TfidfVectorizer(max_features=2500, analyzer='word', stop_words=stopwords, ngram_range=(1,3), dtype=np.float32) \n",
    "# vect_word.fit(Notes)\n",
    "# tfidf_complete = vect_word.transform(Notes)\n",
    "\n",
    "# tfidf = dict(zip(vect_word.get_feature_names(), vect_word.idf_))\n",
    "# tfidf = pd.DataFrame(columns=['Notes_tfidf']).from_dict(dict(tfidf), orient='index')\n",
    "# tfidf.columns = ['Notes_tfidf']\n",
    "\n",
    "# tfidf.sort_values(by=['Notes_tfidf'], ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7283f65-7951-498a-803f-798e3adbda0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['delinq'] = data['mths_since_last_delinq'].apply(lambda x: 0 if pd.isnull(x) else 1)\n",
    "data['record'] = data['mths_since_last_record'].apply(lambda x: 0 if pd.isnull(x) else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a7cb9a4-b9a0-480e-87ed-384d03932ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = data.loc[:, data.columns != 'Notes']\n",
    "final_data = final_data.loc[:, final_data.columns != 'earliest_cr_line']\n",
    "final_data = final_data.loc[:, final_data.columns != 'mths_since_last_delinq']\n",
    "final_data = final_data.loc[:, final_data.columns != 'mths_since_last_record']\n",
    "\n",
    "final_data = final_data.dropna()\n",
    "\n",
    "final_data = pd.get_dummies(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c184ea1e-16a9-4a95-ba6c-4714ee64c7d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_bad</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>debt_to_income</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>...</th>\n",
       "      <th>addr_state_WI</th>\n",
       "      <th>addr_state_WV</th>\n",
       "      <th>addr_state_WY</th>\n",
       "      <th>initial_list_status_f</th>\n",
       "      <th>initial_list_status_m</th>\n",
       "      <th>policy_code_PC1</th>\n",
       "      <th>policy_code_PC2</th>\n",
       "      <th>policy_code_PC3</th>\n",
       "      <th>policy_code_PC4</th>\n",
       "      <th>policy_code_PC5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>10.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12087</td>\n",
       "      <td>12.1</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>39216.0</td>\n",
       "      <td>9.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10114</td>\n",
       "      <td>64.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>11.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81</td>\n",
       "      <td>0.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>57500.0</td>\n",
       "      <td>6.18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10030</td>\n",
       "      <td>37.1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>50004.0</td>\n",
       "      <td>19.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10740</td>\n",
       "      <td>40.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_bad  annual_inc  debt_to_income  delinq_2yrs  inq_last_6mths  open_acc  \\\n",
       "0       0     50000.0           10.87          0.0             0.0      15.0   \n",
       "1       0     39216.0            9.15          0.0             2.0       4.0   \n",
       "2       0     65000.0           11.24          0.0             0.0       4.0   \n",
       "3       0     57500.0            6.18          1.0             0.0       6.0   \n",
       "4       0     50004.0           19.03          0.0             4.0       8.0   \n",
       "\n",
       "   pub_rec  revol_bal  revol_util  total_acc  ...  addr_state_WI  \\\n",
       "0      0.0      12087        12.1       44.0  ...              0   \n",
       "1      0.0      10114        64.0        5.0  ...              0   \n",
       "2      0.0         81         0.6        8.0  ...              0   \n",
       "3      0.0      10030        37.1       23.0  ...              0   \n",
       "4      0.0      10740        40.4       21.0  ...              0   \n",
       "\n",
       "   addr_state_WV  addr_state_WY  initial_list_status_f  initial_list_status_m  \\\n",
       "0              0              0                      1                      0   \n",
       "1              0              0                      1                      0   \n",
       "2              0              0                      1                      0   \n",
       "3              0              0                      1                      0   \n",
       "4              0              0                      1                      0   \n",
       "\n",
       "   policy_code_PC1  policy_code_PC2  policy_code_PC3  policy_code_PC4  \\\n",
       "0                0                0                0                1   \n",
       "1                1                0                0                0   \n",
       "2                0                0                0                1   \n",
       "3                0                1                0                0   \n",
       "4                0                0                1                0   \n",
       "\n",
       "   policy_code_PC5  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f794654c-8ea8-4af5-8c68-06e91941a802",
   "metadata": {},
   "source": [
    "### Test-Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bd63b6b-ce98-41d8-9110-c907bbe9aad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_split(train_data):\n",
    "    return train_test_split(train_data, test_size=0.2, random_state=20, stratify=train_data[['is_bad']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64cca59-e0e9-4cfe-a941-945fe5ab8b86",
   "metadata": {},
   "source": [
    "### Xy_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5832a7d6-9387-4693-90a1-64c739af44bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Xy_split(test,train):\n",
    "    X_train = train.loc[:, train.columns != 'is_bad']\n",
    "    y_train = train.loc[:, train.columns == 'is_bad']\n",
    "    X_test = test.loc[:, test.columns != 'is_bad']\n",
    "    y_test = test.loc[:, test.columns == 'is_bad']\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0612b9-a9fa-4838-90b8-a244d00d5693",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29767564-efea-4452-be0c-23614aff687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg(train, test, smote):\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = Xy_split(test,train)\n",
    "    \n",
    "    X_train = pd.DataFrame(scaler.fit_transform(X_train))\n",
    "    X_test = pd.DataFrame(scaler.transform(X_test))\n",
    "    \n",
    "    if smote == \"yes\":\n",
    "        sm = SMOTE(random_state=42)\n",
    "        X_smote, y_smote = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "        model = LogisticRegression(random_state=20)\n",
    "        solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "        penalty = ['l2']\n",
    "        c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "        grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "        cv = StratifiedKFold(n_splits=5)\n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='precision',error_score=0)\n",
    "        grid_result = grid_search.fit(X_train, y_train)\n",
    "\n",
    "        y_pred=grid_result.predict(X_test)\n",
    "\n",
    "        print (\"Logistic Regression\")\n",
    "        print (classification_report(y_test, y_pred))\n",
    "    if smote == 'no':\n",
    "        model = LogisticRegression(random_state=20)\n",
    "        solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "        penalty = ['l2']\n",
    "        c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "        grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "        cv = StratifiedKFold(n_splits=5)\n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='precision',error_score=0)\n",
    "        grid_result = grid_search.fit(X_train, y_train)\n",
    "\n",
    "        y_pred=grid_result.predict(X_test)\n",
    "\n",
    "        print (\"Logistic Regression\")\n",
    "        print (classification_report(y_test, y_pred))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d29142b-7933-4c25-8287-1405ca6cd039",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35d3e0dc-4fde-4331-a7c9-33d6e4f53def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(train, test):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = Xy_split(test,train)\n",
    "    \n",
    "    model = RandomForestClassifier(random_state=20)\n",
    "    cv = StratifiedKFold(n_splits=5)\n",
    "    parameter = dict()\n",
    "    parameter['n_estimators'] = [10, 50, 100, 200]\n",
    "    parameter['max_features'] = ['auto', 'sqrt', 'log2']\n",
    "    parameter['max_depth'] = [5, 10, 25]\n",
    "\n",
    "    # Model fitting\n",
    "    grid_search = GridSearchCV(model, parameter, scoring='precision', n_jobs=-1, cv=cv,error_score=0)\n",
    "    grid_result = grid_search.fit(X_train, y_train)\n",
    "\n",
    "    y_pred=grid_result.predict(X_test)\n",
    "\n",
    "    print (\"Random Forest Classifier\")\n",
    "    print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da91446c-4267-42ad-86c9-a5a7cd97f7e1",
   "metadata": {},
   "source": [
    "### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "838e4d53-2455-4fae-a36e-78fe8a97fe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_classifier(train, test):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = Xy_split(test,train)\n",
    "    \n",
    "    svc = LinearSVC(random_state=20)\n",
    "    cv = StratifiedKFold(n_splits=5)\n",
    "    loss = ['hinge', 'squared_hinge']\n",
    "    max_iter = [10, 20, 50, 100]\n",
    "    penalty = ['l1', 'l2']\n",
    "    C = [0.01, 0.1, 1, 10, 100]\n",
    "    parameters = dict(loss=loss,penalty=penalty,max_iter=max_iter, C=C)\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=svc, param_grid=parameters,  n_jobs=-1, cv=cv, scoring='precision',error_score=0)\n",
    "    grid_result = grid_search.fit(X_train, y_train)\n",
    "\n",
    "    y_pred=grid_result.predict(X_test)\n",
    "\n",
    "    print (\"SVM Classifier\")\n",
    "    print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d933c4a-4c03-415e-9dd4-12ebbce8c77d",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec0abe54-7431-4e3a-bd3b-379f963f54b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lightgbm(train, test):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = Xy_split(test,train)\n",
    "    \n",
    "    model = lgb.LGBMClassifier(random_state=20)\n",
    "    cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "    parameter = dict()\n",
    "    parameter['n_estimators'] = [10, 50, 100, 200]\n",
    "    parameter['max_depth'] = [5, 10, 25, 50, 100]\n",
    "    parameter['learning_rate'] = [0.01, 0.1, 1, 5,10]\n",
    "\n",
    "    # Model fitting\n",
    "    grid_search = GridSearchCV(model, parameter, scoring='precision', n_jobs=-1, cv=cv,error_score=0)\n",
    "    grid_result = grid_search.fit(X_train, y_train)\n",
    "\n",
    "    y_pred=grid_result.predict(X_test)\n",
    "\n",
    "    print (\"Random Forest Classifier\")\n",
    "    print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a12bbd0-1d14-4701-bd04-64290be41964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      1732\n",
      "           1       0.97      0.14      0.24       258\n",
      "\n",
      "    accuracy                           0.89      1990\n",
      "   macro avg       0.93      0.57      0.59      1990\n",
      "weighted avg       0.90      0.89      0.85      1990\n",
      "\n",
      "Random Forest Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93      1732\n",
      "           1       1.00      0.04      0.08       258\n",
      "\n",
      "    accuracy                           0.88      1990\n",
      "   macro avg       0.94      0.52      0.51      1990\n",
      "weighted avg       0.89      0.88      0.82      1990\n",
      "\n",
      "SVM Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93      1732\n",
      "           1       0.00      0.00      0.00       258\n",
      "\n",
      "    accuracy                           0.87      1990\n",
      "   macro avg       0.44      0.50      0.47      1990\n",
      "weighted avg       0.76      0.87      0.81      1990\n",
      "\n",
      "Random Forest Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94      1732\n",
      "           1       1.00      0.12      0.21       258\n",
      "\n",
      "    accuracy                           0.89      1990\n",
      "   macro avg       0.94      0.56      0.57      1990\n",
      "weighted avg       0.90      0.89      0.84      1990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train, test = test_train_split(final_data)\n",
    "\n",
    "log_reg(train, test, \"no\")\n",
    "random_forest(train, test)\n",
    "svm_classifier(train, test)\n",
    "lightgbm(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c863e3-738a-4f1a-92d9-ffc41d608be4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ec75754-103d-429f-9851-43caf8c19a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random over-sampling:\n",
      "0    6924\n",
      "1    6924\n",
      "Name: is_bad, dtype: int64\n",
      "Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.72      0.80      1732\n",
      "           1       0.22      0.53      0.31       258\n",
      "\n",
      "    accuracy                           0.69      1990\n",
      "   macro avg       0.57      0.63      0.56      1990\n",
      "weighted avg       0.82      0.69      0.74      1990\n",
      "\n",
      "Random Forest Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      1732\n",
      "           1       0.91      0.15      0.26       258\n",
      "\n",
      "    accuracy                           0.89      1990\n",
      "   macro avg       0.90      0.57      0.60      1990\n",
      "weighted avg       0.89      0.89      0.85      1990\n",
      "\n",
      "SVM Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1732\n",
      "           1       0.13      1.00      0.23       258\n",
      "\n",
      "    accuracy                           0.13      1990\n",
      "   macro avg       0.06      0.50      0.11      1990\n",
      "weighted avg       0.02      0.13      0.03      1990\n",
      "\n",
      "Random Forest Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93      1732\n",
      "           1       0.47      0.20      0.28       258\n",
      "\n",
      "    accuracy                           0.87      1990\n",
      "   macro avg       0.68      0.58      0.60      1990\n",
      "weighted avg       0.84      0.87      0.84      1990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train, test = test_train_split(final_data)\n",
    "\n",
    "count_class_0, count_class_1 = train.is_bad.value_counts()\n",
    "\n",
    "class_0 = train[train['is_bad'] == 0]\n",
    "class_1 = train[train['is_bad'] == 1]\n",
    "\n",
    "class_1_over = class_1.sample(count_class_0, replace=True)\n",
    "train = pd.concat([class_0, class_1_over], axis=0)\n",
    "\n",
    "print('Random over-sampling:')\n",
    "print(train.is_bad.value_counts())\n",
    "\n",
    "log_reg(train, test, \"no\")\n",
    "random_forest(train, test)\n",
    "svm_classifier(train, test)\n",
    "lightgbm(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a61847-ff72-46ce-8abb-3a083e9623d3",
   "metadata": {},
   "source": [
    "### Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e26d1fa-508f-4361-83e0-9aee2d0ffbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random under-sampling:\n",
      "0    1034\n",
      "1    1034\n",
      "Name: is_bad, dtype: int64\n",
      "Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.68      0.78      1732\n",
      "           1       0.19      0.50      0.28       258\n",
      "\n",
      "    accuracy                           0.66      1990\n",
      "   macro avg       0.55      0.59      0.53      1990\n",
      "weighted avg       0.81      0.66      0.71      1990\n",
      "\n",
      "Random Forest Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.75      0.82      1732\n",
      "           1       0.23      0.50      0.31       258\n",
      "\n",
      "    accuracy                           0.72      1990\n",
      "   macro avg       0.57      0.62      0.57      1990\n",
      "weighted avg       0.82      0.72      0.76      1990\n",
      "\n",
      "SVM Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93      1732\n",
      "           1       0.00      0.00      0.00       258\n",
      "\n",
      "    accuracy                           0.87      1990\n",
      "   macro avg       0.44      0.50      0.47      1990\n",
      "weighted avg       0.76      0.87      0.81      1990\n",
      "\n",
      "Random Forest Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.68      0.78      1732\n",
      "           1       0.20      0.53      0.29       258\n",
      "\n",
      "    accuracy                           0.66      1990\n",
      "   macro avg       0.55      0.61      0.53      1990\n",
      "weighted avg       0.82      0.66      0.71      1990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train, test = test_train_split(final_data)\n",
    "\n",
    "count_class_0, count_class_1 = train.is_bad.value_counts()\n",
    "\n",
    "class_0 = train[train['is_bad'] == 0]\n",
    "class_1 = train[train['is_bad'] == 1]\n",
    "\n",
    "class_0_under = class_0.sample(count_class_1, replace=True)\n",
    "train = pd.concat([class_0_under, class_1], axis=0)\n",
    "\n",
    "print('Random under-sampling:')\n",
    "print(train.is_bad.value_counts())\n",
    "\n",
    "log_reg(train, test,\"no\")\n",
    "random_forest(train, test)\n",
    "svm_classifier(train, test)\n",
    "lightgbm(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a04c489-301a-4fcc-8a1e-7c5079b16278",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07572fde-f101-4b86-9226-4a3c2b33fe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X = final_data.loc[:, final_data.columns != 'is_bad']\n",
    "y = final_data.loc[:, final_data.columns == 'is_bad']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y, random_state=20)\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_smote, y_smote = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "train = pd.concat([X_smote, y_smote], axis=1)\n",
    "test = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4510fe43-3ea4-4634-a7e8-0c85d7ea76f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      1732\n",
      "           1       0.97      0.15      0.26       258\n",
      "\n",
      "    accuracy                           0.89      1990\n",
      "   macro avg       0.93      0.57      0.60      1990\n",
      "weighted avg       0.90      0.89      0.85      1990\n",
      "\n",
      "Random Forest Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93      1732\n",
      "           1       0.80      0.02      0.03       258\n",
      "\n",
      "    accuracy                           0.87      1990\n",
      "   macro avg       0.84      0.51      0.48      1990\n",
      "weighted avg       0.86      0.87      0.81      1990\n",
      "\n",
      "SVM Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1732\n",
      "           1       0.13      1.00      0.23       258\n",
      "\n",
      "    accuracy                           0.13      1990\n",
      "   macro avg       0.06      0.50      0.11      1990\n",
      "weighted avg       0.02      0.13      0.03      1990\n",
      "\n",
      "Random Forest Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93      1732\n",
      "           1       0.86      0.07      0.13       258\n",
      "\n",
      "    accuracy                           0.88      1990\n",
      "   macro avg       0.87      0.53      0.53      1990\n",
      "weighted avg       0.88      0.88      0.83      1990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_reg(train, test,\"yes\")\n",
    "random_forest(train, test)\n",
    "svm_classifier(train, test)\n",
    "lightgbm(train, test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
